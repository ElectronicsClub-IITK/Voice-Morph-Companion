{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests and Decision Trees\n",
    "- Classify the Spotify.csv dataset \n",
    "- Predict the Genre \n",
    "- The dataset has 23 Columns and The Output feature is **playlist_genre** so all others can be used as input features. Decide on what can be used and what cannot be used. \n",
    "- Do the Preprocessing below\n",
    "- Do 70:30 Train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlist_subgenre</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>insttrack_id</th>\n",
       "      <th>rumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26210</th>\n",
       "      <td>325</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14615</th>\n",
       "      <td>234</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.778562</td>\n",
       "      <td>-0.247959</td>\n",
       "      <td>-1.213971</td>\n",
       "      <td>1.354641</td>\n",
       "      <td>-1.136007</td>\n",
       "      <td>-0.374288</td>\n",
       "      <td>-0.536933</td>\n",
       "      <td>1.141738</td>\n",
       "      <td>1.234829</td>\n",
       "      <td>-1.343402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21824</th>\n",
       "      <td>361</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0.599293</td>\n",
       "      <td>0.253453</td>\n",
       "      <td>1.277014</td>\n",
       "      <td>0.147626</td>\n",
       "      <td>-1.136007</td>\n",
       "      <td>-0.374288</td>\n",
       "      <td>0.198889</td>\n",
       "      <td>-0.112104</td>\n",
       "      <td>0.523537</td>\n",
       "      <td>1.263229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>368</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.786375</td>\n",
       "      <td>0.881596</td>\n",
       "      <td>-1.213971</td>\n",
       "      <td>0.871835</td>\n",
       "      <td>-1.136007</td>\n",
       "      <td>-0.374288</td>\n",
       "      <td>-0.549956</td>\n",
       "      <td>-1.297243</td>\n",
       "      <td>1.970826</td>\n",
       "      <td>-0.012461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19283</th>\n",
       "      <td>314</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1.006097</td>\n",
       "      <td>-0.815492</td>\n",
       "      <td>0.723462</td>\n",
       "      <td>-0.140577</td>\n",
       "      <td>0.880276</td>\n",
       "      <td>-0.373703</td>\n",
       "      <td>-0.458793</td>\n",
       "      <td>0.635048</td>\n",
       "      <td>-0.848005</td>\n",
       "      <td>-0.669166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22969</th>\n",
       "      <td>448</td>\n",
       "      <td>470</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.013218</td>\n",
       "      <td>1.526269</td>\n",
       "      <td>-0.106866</td>\n",
       "      <td>0.658040</td>\n",
       "      <td>-1.136007</td>\n",
       "      <td>0.061670</td>\n",
       "      <td>1.025874</td>\n",
       "      <td>-1.580645</td>\n",
       "      <td>0.261240</td>\n",
       "      <td>-0.939874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22976</th>\n",
       "      <td>448</td>\n",
       "      <td>470</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.607331</td>\n",
       "      <td>-0.055108</td>\n",
       "      <td>1.000238</td>\n",
       "      <td>-1.280928</td>\n",
       "      <td>0.880276</td>\n",
       "      <td>1.542306</td>\n",
       "      <td>-0.445769</td>\n",
       "      <td>0.489053</td>\n",
       "      <td>-0.777821</td>\n",
       "      <td>0.692932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22978</th>\n",
       "      <td>448</td>\n",
       "      <td>470</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.406233</td>\n",
       "      <td>0.666705</td>\n",
       "      <td>-1.490747</td>\n",
       "      <td>1.314239</td>\n",
       "      <td>0.880276</td>\n",
       "      <td>-0.374288</td>\n",
       "      <td>1.637973</td>\n",
       "      <td>0.042479</td>\n",
       "      <td>-0.777228</td>\n",
       "      <td>-0.920249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22981</th>\n",
       "      <td>448</td>\n",
       "      <td>470</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.455641</td>\n",
       "      <td>-0.578561</td>\n",
       "      <td>0.446686</td>\n",
       "      <td>-0.389050</td>\n",
       "      <td>-1.136007</td>\n",
       "      <td>-0.374288</td>\n",
       "      <td>-0.833866</td>\n",
       "      <td>-0.700379</td>\n",
       "      <td>0.750520</td>\n",
       "      <td>-0.200349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22982</th>\n",
       "      <td>448</td>\n",
       "      <td>470</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>-1.703635</td>\n",
       "      <td>1.515249</td>\n",
       "      <td>-0.937195</td>\n",
       "      <td>1.092700</td>\n",
       "      <td>0.880276</td>\n",
       "      <td>-0.367089</td>\n",
       "      <td>-0.829959</td>\n",
       "      <td>-0.352567</td>\n",
       "      <td>1.450906</td>\n",
       "      <td>0.256204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29888 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       playlist_subgenre  danceability  energy  key  loudness      mode  \\\n",
       "26210                325           136       3   13       NaN       NaN   \n",
       "14615                234            72       5   15  0.778562 -0.247959   \n",
       "21824                361             5       3   23  0.599293  0.253453   \n",
       "2781                 368           147       2    5 -1.786375  0.881596   \n",
       "19283                314           236       1   19  1.006097 -0.815492   \n",
       "...                  ...           ...     ...  ...       ...       ...   \n",
       "22969                448           470       6   24  0.013218  1.526269   \n",
       "22976                448           470       6   24 -0.607331 -0.055108   \n",
       "22978                448           470       6   24  0.406233  0.666705   \n",
       "22981                448           470       6   24 -0.455641 -0.578561   \n",
       "22982                448           470       6   24 -1.703635  1.515249   \n",
       "\n",
       "       speechiness  acousticness  insttrack_id  rumentalness  liveness  \\\n",
       "26210          NaN           NaN           NaN           NaN       NaN   \n",
       "14615    -1.213971      1.354641     -1.136007     -0.374288 -0.536933   \n",
       "21824     1.277014      0.147626     -1.136007     -0.374288  0.198889   \n",
       "2781     -1.213971      0.871835     -1.136007     -0.374288 -0.549956   \n",
       "19283     0.723462     -0.140577      0.880276     -0.373703 -0.458793   \n",
       "...            ...           ...           ...           ...       ...   \n",
       "22969    -0.106866      0.658040     -1.136007      0.061670  1.025874   \n",
       "22976     1.000238     -1.280928      0.880276      1.542306 -0.445769   \n",
       "22978    -1.490747      1.314239      0.880276     -0.374288  1.637973   \n",
       "22981     0.446686     -0.389050     -1.136007     -0.374288 -0.833866   \n",
       "22982    -0.937195      1.092700      0.880276     -0.367089 -0.829959   \n",
       "\n",
       "        valence     tempo  duration_ms  \n",
       "26210       NaN       NaN          NaN  \n",
       "14615  1.141738  1.234829    -1.343402  \n",
       "21824 -0.112104  0.523537     1.263229  \n",
       "2781  -1.297243  1.970826    -0.012461  \n",
       "19283  0.635048 -0.848005    -0.669166  \n",
       "...         ...       ...          ...  \n",
       "22969 -1.580645  0.261240    -0.939874  \n",
       "22976  0.489053 -0.777821     0.692932  \n",
       "22978  0.042479 -0.777228    -0.920249  \n",
       "22981 -0.700379  0.750520    -0.200349  \n",
       "22982 -0.352567  1.450906     0.256204  \n",
       "\n",
       "[29888 rows x 14 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "\n",
    "df = pd.read_csv('spotify.csv')\n",
    "X = df.drop(columns=['playlist_genre'])\n",
    "y = df['playlist_genre']\n",
    "columns_to_drop = [\n",
    "    'track_album_id', 'track_album_name', 'track_album_release_date',\n",
    "    'playlist_name', 'playlist_id', 'track_name', 'track_artist','track_popularity']\n",
    "X= X.drop(columns=columns_to_drop)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X.apply(lambda s: pd.to_numeric(s, errors='coerce').notnull().all())\n",
    "#numeric or not playlist_subgenre    False\n",
    "#danceability         False\n",
    "#energy               False\n",
    "#key                  False\n",
    "#loudness              True\n",
    "#mode                  True\n",
    "#speechiness           True\n",
    "#acousticness          True\n",
    "#insttrack_id          True\n",
    "#rumentalness          True\n",
    "#liveness              True\n",
    "#valence               True\n",
    "#tempo                 True\n",
    "#duration_ms           True\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X1_train = X_train.loc[:,[\"loudness\",\"mode\",\"speechiness\",\"acousticness\",\"insttrack_id\",\"rumentalness\",\"liveness\",\"valence\",\"tempo\",\"duration_ms\"]]\n",
    "scaler = StandardScaler()\n",
    "X1_train = pd.DataFrame(scaler.fit_transform(X1_train), columns=X1_train.columns)\n",
    "X_train = X_train.drop([\"loudness\",\"mode\",\"speechiness\",\"acousticness\",\"insttrack_id\",\"rumentalness\",\"liveness\",\"valence\",\"tempo\",\"duration_ms\"],axis=1)\n",
    "X2_train = pd.concat([X_train,X1_train],axis=1)\n",
    "for col in ['playlist_subgenre', 'key','danceability', 'energy']:\n",
    "    X2_train[col] = label_encoder.fit_transform(X2_train[col])\n",
    "X2_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame a Decision Tree Model \n",
    "- Use Any Parameters\n",
    "- You can use any library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Define a Decision Tree class\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth, min_samples_split):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = {}\n",
    "\n",
    "    def entropy(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / len(y)\n",
    "        entropy = sum(probabilities * -np.log2(probabilities))\n",
    "        return entropy\n",
    "\n",
    "    def information_gain(self, X_column, y, threshold):\n",
    "        left_idxs, right_idxs = self.split(X_column, threshold)\n",
    "        left_y = y[left_idxs]\n",
    "        right_y = y[right_idxs]\n",
    "        child_entropy = self.entropy(left_y) + self.entropy(right_y)\n",
    "        ig = self.entropy(y) - child_entropy\n",
    "        return ig\n",
    "\n",
    "    def split(self, X_column, threshold):\n",
    "        left_idxs = np.argwhere(X_column <= threshold).flatten()\n",
    "        right_idxs = np.argwhere(X_column > threshold).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "\n",
    "    def most_common_label(self, y):\n",
    "        counter = counter(y)\n",
    "        most_common = counter.most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "    def find_split_point(self, X, y):\n",
    "        \n",
    "        best_gain = -1\n",
    "        best_column = None\n",
    "        best_threshold = None\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        for column in range(1,n_features):\n",
    "            \n",
    "            X_column = X.iloc[:, column]\n",
    "            thresholds = np.unique(X_column)\n",
    "                \n",
    "        for threshold in thresholds:\n",
    "            ig = self.information_gain(X_column, y, threshold)\n",
    "\n",
    "            if ig > best_gain:\n",
    "                best_gain = ig\n",
    "                best_column = column\n",
    "                best_threshold = threshold\n",
    "\n",
    "        return best_column, best_threshold\n",
    "\n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        if depth == self.max_depth or len(y) < self.min_samples_split:\n",
    "            self.tree['label'] = self.most_common_label(y)\n",
    "            return\n",
    "        column, threshold = self.find_split_point(X, y)\n",
    "        self.tree['feature_idx'] = column\n",
    "        self.tree['split_point'] = threshold\n",
    "        left_idxs, right_idxs = self.split(X[:, column], threshold)\n",
    "        self.tree['left_split'] = {}\n",
    "        self.tree['right_split'] = {}\n",
    "        self.build_tree(X[left_idxs], y[left_idxs], depth=depth+1)\n",
    "        self.build_tree(X[right_idxs], y[right_idxs], depth=depth+1)\n",
    "\n",
    "    def predict_tree(self, X_test):\n",
    "        feature_idx = self.tree['feature_idx']\n",
    "        if X_test[feature_idx] <= self.tree['split_point']:\n",
    "            if 'left_split' in self.tree:\n",
    "                return self.predict_tree(self.tree['left_split'], X_test)\n",
    "            else:\n",
    "                return self.tree['label']\n",
    "        else:\n",
    "            if 'right_split' in self.tree:\n",
    "                return self.predict_tree(self.tree['right_split'], X_test)\n",
    "            else:\n",
    "                return self.tree['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame a Random Forests Model \n",
    "- Use Any Parameters\n",
    "- You can use any library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Random Forest class\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees, max_depth, min_samples_split, max_features):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "\n",
    "    def build_trees(self, X, y):\n",
    "        for i in range(self.n_trees):\n",
    "            tree = DecisionTree(self.max_depth, self.min_samples_split)\n",
    "            column_idxs = np.random.choice(X.shape[1], self.max_features, replace=False)\n",
    "            print(column_idxs)\n",
    "            X_column_subset = X.iloc[:, column_idxs]\n",
    "            tree.build_tree(X_column_subset, y)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict_rf(self, X_test):\n",
    "        ensemble_preds = [tree.predict_tree(X_test) for tree in self.trees]\n",
    "        final_pred = max(ensemble_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Models and Report the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13  9  5]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 22983 is out of bounds for axis 0 with size 22983",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      2\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForest(n_trees \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_trees\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX2_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m X1_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mloc[:,[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloudness\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeechiness\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macousticness\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minsttrack_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrumentalness\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliveness\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalence\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtempo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduration_ms\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      5\u001b[0m X1_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scaler\u001b[38;5;241m.\u001b[39mtransform(X1_test), columns\u001b[38;5;241m=\u001b[39mX1_test\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "Cell \u001b[1;32mIn[99], line 16\u001b[0m, in \u001b[0;36mRandomForest.build_trees\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(column_idxs)\n\u001b[0;32m     15\u001b[0m X_column_subset \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[:, column_idxs]\n\u001b[1;32m---> 16\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_column_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees\u001b[38;5;241m.\u001b[39mappend(tree)\n",
      "Cell \u001b[1;32mIn[98], line 64\u001b[0m, in \u001b[0;36mDecisionTree.build_tree\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmost_common_label(y)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m column, threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_split_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_idx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m column\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit_point\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m threshold\n",
      "Cell \u001b[1;32mIn[98], line 51\u001b[0m, in \u001b[0;36mDecisionTree.find_split_point\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     48\u001b[0m     thresholds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(X_column)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[1;32m---> 51\u001b[0m     ig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minformation_gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ig \u001b[38;5;241m>\u001b[39m best_gain:\n\u001b[0;32m     54\u001b[0m         best_gain \u001b[38;5;241m=\u001b[39m ig\n",
      "Cell \u001b[1;32mIn[98], line 22\u001b[0m, in \u001b[0;36mDecisionTree.information_gain\u001b[1;34m(self, X_column, y, threshold)\u001b[0m\n\u001b[0;32m     20\u001b[0m left_idxs, right_idxs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit(X_column, threshold)\n\u001b[0;32m     21\u001b[0m left_y \u001b[38;5;241m=\u001b[39m y[left_idxs]\n\u001b[1;32m---> 22\u001b[0m right_y \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mright_idxs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     23\u001b[0m child_entropy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentropy(left_y) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentropy(right_y)\n\u001b[0;32m     24\u001b[0m ig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentropy(y) \u001b[38;5;241m-\u001b[39m child_entropy\n",
      "\u001b[1;31mIndexError\u001b[0m: index 22983 is out of bounds for axis 0 with size 22983"
     ]
    }
   ],
   "source": [
    "import math\n",
    "rf = RandomForest(n_trees =100,max_features=3,max_depth=5,min_samples_split=2)\n",
    "rf.build_trees(X2_train,y_train)\n",
    "X1_test = X_test.loc[:,[\"loudness\",\"mode\",\"speechiness\",\"acousticness\",\"insttrack_id\",\"rumentalness\",\"liveness\",\"valence\",\"tempo\",\"duration_ms\"]]\n",
    "X1_test = pd.DataFrame(scaler.transform(X1_test), columns=X1_test.columns)\n",
    "X_test = X_test.drop([\"loudness\",\"mode\",\"speechiness\",\"acousticness\",\"insttrack_id\",\"rumentalness\",\"liveness\",\"valence\",\"tempo\",\"duration_ms\"],axis=1)\n",
    "X2_test = pd.concat([X_test,X1_test],axis=1)\n",
    "for col in ['playlist_subgenre', 'key','danceability', 'energy']:\n",
    "    X2_test[col] = label_encoder.transform(X2_train[col])\n",
    "X2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7416573867739413"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
