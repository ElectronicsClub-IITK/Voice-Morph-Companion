{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4nORi3aWpVu"
      },
      "source": [
        "# Question 1. Load the Cifar-100 dataset\n",
        "1. Load the cifar 100 dataset. Use the 'coarse' labels.\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/cifar100/load_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3q7vJ076N-f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aso3EuY7B8ZB"
      },
      "source": [
        "2. Check if there are 20 labels in y_train using np.unique()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sM3HbhoW6Pp0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk1NMluxsd8b"
      },
      "source": [
        "3. More information about the dataset could be found here : https://www.cs.toronto.edu/~kriz/cifar.html . Plot the first 25 images from both the train and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32lj4Fi_6R0o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppI2o5y8PFgx"
      },
      "source": [
        "4. Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBsc3ZR66S1w"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ5E_2tNUPTX"
      },
      "source": [
        "It can be seen that the model couldn't achieve a good accuracy. We need to use better models for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1Qa7q3ytj8_"
      },
      "source": [
        "# Question 2 : Implement VGGNet - Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_sltz7Bl8G9"
      },
      "source": [
        "Check this website : https://paperswithcode.com/sota/image-classification-on-cifar-100 . It contains information about the best performing models.\n",
        "\n",
        "We can check the VGGNet-16 model. It consists of 16 layers with weights and some maxpooling layers. The architecture could be in the internet (even in the slides).\n",
        "\n",
        "VGGNet works on images of size (224,224,3). However, we can implement it on (32,32,3). We will see both the approaches. First let's build VGGNet and train it on original image. Then, we will reshape our images from (32,32,3) to (224,224,3) and train VGGNet on them.\n",
        "\n",
        "The layers are :\n",
        "\n",
        "1. Conv layer : 64 kernels, 3x3 . strides = (1,1). activation =none. Batch Normalization. Relu Activation.\n",
        "2. Conv layer : 64 kernels, 3x3 . strides = (1,1). activation =none. Batch Normalization. Relu Activation.\n",
        "3. MaxPooling . kernel = 2x2. strides = (2,2).\n",
        "4. Conv layer : 128 kernels, 3x3 . strides = (1,1). activation =none.\n",
        " Batch Normalization. Relu Activation.\n",
        "5. Conv layer : 128 kernels, 3x3 . strides = (1,1). activation =none.\n",
        " Batch Normalization. Relu Activation.\n",
        "6. MaxPooling . kernel = 2x2. strides = (2,2).\n",
        "7. Conv layer : 256 kernels, 3x3 . strides = (1,1). activation =none.\n",
        " Batch Normalization. Relu Activation.\n",
        "8. Conv layer : 256 kernels, 3x3 . strides = (1,1). activation =none.\n",
        " Batch Normalization. Relu Activation.\n",
        "9. Conv layer : 256 kernels, 3x3 . strides = (1,1). activation =none.\n",
        " Batch Normalization. Relu Activation.\n",
        "10. MaxPooling . kernel = 2x2. strides = (2,2).\n",
        "11. Conv layer : 512 kernels, 3x3 . strides = (1,1). activation =none.\n",
        " Batch Normalization. Relu Activation.\n",
        "12. Conv layer : 512 kernels, 3x3 . strides = (1,1). activation =none.\n",
        " Batch Normalization. Relu Activation.\n",
        "13. Conv layer : 512 kernels, 3x3 . strides = (1,1). activation =none.\n",
        " Batch Normalization. Relu Activation.\n",
        "14. MaxPooling . kernel = 2x2. strides = (2,2).\n",
        "15. Flatten Layer.\n",
        "16. Dense layer of 4096 neurons.\n",
        "17. Dense layer of 1000 neurons.\n",
        "18. Dense layer of 20 neurons.\n",
        "\n",
        "\n",
        "I have omitted the last block of three conv layers of 512 kernels because the output sizes reduces to (1,1,512). You may include it and see.\n",
        "\n",
        "The order of convolution, batch normalization and relu activation matters. If you do relu activation before normalization, it may happen that your loss fails to backpropagate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjgtmbZa60ug"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1YjMQq81DgA"
      },
      "source": [
        "Once you are ready with the model, change runtime to GPU and then train the model, else it will take a lot of time to train it on CPU.\n",
        "\n",
        "Compile the model using SparseCategoricalCrossentropy Loss Function and accuracy metric. Fit it on the train dataset. and evaluate on the test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uRBxCwAcyFq",
        "outputId": "202b30f9-60dc-444a-94c2-c853998f1a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 60s 7ms/step - loss: 1.5216 - accuracy: 0.5635\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.5216360092163086, 0.5634999871253967]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
