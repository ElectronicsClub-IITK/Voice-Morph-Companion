{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Family</th>\n",
       "      <th>Instrument (abbr.)</th>\n",
       "      <th>Instrument (in full)</th>\n",
       "      <th>Technique (abbr.)</th>\n",
       "      <th>Technique (in full)</th>\n",
       "      <th>Pitch</th>\n",
       "      <th>Pitch ID</th>\n",
       "      <th>Dynamics</th>\n",
       "      <th>Dynamics ID</th>\n",
       "      <th>Instance ID</th>\n",
       "      <th>String ID (if applicable)</th>\n",
       "      <th>Needed digital retuning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brass/Bass_Tuba/ordinario/BTb-ord-F#1-pp-N-N.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>Brass</td>\n",
       "      <td>BTb</td>\n",
       "      <td>Bass Tuba</td>\n",
       "      <td>ord</td>\n",
       "      <td>ordinario</td>\n",
       "      <td>F#1</td>\n",
       "      <td>30</td>\n",
       "      <td>pp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brass/Bass_Tuba/ordinario/BTb-ord-G1-pp-N-R100...</td>\n",
       "      <td>4</td>\n",
       "      <td>Brass</td>\n",
       "      <td>BTb</td>\n",
       "      <td>Bass Tuba</td>\n",
       "      <td>ord</td>\n",
       "      <td>ordinario</td>\n",
       "      <td>G1</td>\n",
       "      <td>31</td>\n",
       "      <td>pp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brass/Bass_Tuba/ordinario/BTb-ord-G#1-pp-N-T16...</td>\n",
       "      <td>3</td>\n",
       "      <td>Brass</td>\n",
       "      <td>BTb</td>\n",
       "      <td>Bass Tuba</td>\n",
       "      <td>ord</td>\n",
       "      <td>ordinario</td>\n",
       "      <td>G#1</td>\n",
       "      <td>32</td>\n",
       "      <td>pp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brass/Bass_Tuba/ordinario/BTb-ord-A1-pp-N-T23d...</td>\n",
       "      <td>2</td>\n",
       "      <td>Brass</td>\n",
       "      <td>BTb</td>\n",
       "      <td>Bass Tuba</td>\n",
       "      <td>ord</td>\n",
       "      <td>ordinario</td>\n",
       "      <td>A1</td>\n",
       "      <td>33</td>\n",
       "      <td>pp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass/Bass_Tuba/ordinario/BTb-ord-A#1-pp-N-N.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>Brass</td>\n",
       "      <td>BTb</td>\n",
       "      <td>Bass Tuba</td>\n",
       "      <td>ord</td>\n",
       "      <td>ordinario</td>\n",
       "      <td>A#1</td>\n",
       "      <td>34</td>\n",
       "      <td>pp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  Fold Family  \\\n",
       "0   Brass/Bass_Tuba/ordinario/BTb-ord-F#1-pp-N-N.wav     2  Brass   \n",
       "1  Brass/Bass_Tuba/ordinario/BTb-ord-G1-pp-N-R100...     4  Brass   \n",
       "2  Brass/Bass_Tuba/ordinario/BTb-ord-G#1-pp-N-T16...     3  Brass   \n",
       "3  Brass/Bass_Tuba/ordinario/BTb-ord-A1-pp-N-T23d...     2  Brass   \n",
       "4   Brass/Bass_Tuba/ordinario/BTb-ord-A#1-pp-N-N.wav     0  Brass   \n",
       "\n",
       "  Instrument (abbr.) Instrument (in full) Technique (abbr.)  \\\n",
       "0                BTb            Bass Tuba               ord   \n",
       "1                BTb            Bass Tuba               ord   \n",
       "2                BTb            Bass Tuba               ord   \n",
       "3                BTb            Bass Tuba               ord   \n",
       "4                BTb            Bass Tuba               ord   \n",
       "\n",
       "  Technique (in full) Pitch  Pitch ID Dynamics  Dynamics ID  Instance ID  \\\n",
       "0           ordinario   F#1        30       pp            0            0   \n",
       "1           ordinario    G1        31       pp            0            0   \n",
       "2           ordinario   G#1        32       pp            0            0   \n",
       "3           ordinario    A1        33       pp            0            0   \n",
       "4           ordinario   A#1        34       pp            0            0   \n",
       "\n",
       "   String ID (if applicable)  Needed digital retuning  \n",
       "0                        NaN                    False  \n",
       "1                        NaN                     True  \n",
       "2                        NaN                     True  \n",
       "3                        NaN                     True  \n",
       "4                        NaN                    False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tqdm\n",
    "metadata = pd.read_csv('TinySOL_metadata (1).csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    audio, sample_rate = librosa.load(file, res_type='scipy') \n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2913it [04:35, 10.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = str(row[\"Path\"])\n",
    "    final_class_labels=row[\"Instrument (in full)\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-796.161, 154.30495, 115.17337, 69.384094, 33...</td>\n",
       "      <td>Bass Tuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-780.7726, 155.0216, 114.37417, 66.248245, 28...</td>\n",
       "      <td>Bass Tuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-737.51624, 197.43735, 118.784454, 46.450912,...</td>\n",
       "      <td>Bass Tuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-779.69147, 155.60567, 113.64972, 64.04005, 2...</td>\n",
       "      <td>Bass Tuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-745.1969, 203.65991, 119.42016, 43.040768, 4...</td>\n",
       "      <td>Bass Tuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature      class\n",
       "0  [-796.161, 154.30495, 115.17337, 69.384094, 33...  Bass Tuba\n",
       "1  [-780.7726, 155.0216, 114.37417, 66.248245, 28...  Bass Tuba\n",
       "2  [-737.51624, 197.43735, 118.784454, 46.450912,...  Bass Tuba\n",
       "3  [-779.69147, 155.60567, 113.64972, 64.04005, 2...  Bass Tuba\n",
       "4  [-745.1969, 203.65991, 119.42016, 43.040768, 4...  Bass Tuba"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to Pandas dataframe\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split the dataset into independent and dependent dataset\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Label Encoding\n",
    "###y=np.array(pd.get_dummies(y))\n",
    "### Label Encoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X to match the input shape expected by Conv2D\n",
    "X = X.reshape(X.shape[0], 40, 1, 1)  # (number_of_samples, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense\n",
    "model = Sequential([\n",
    "    Conv1D(32, 3, activation='relu', input_shape=(40, 1)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(y.shape[1],activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.3744 - loss: 7.9363  \n",
      "Epoch 2/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.3184\n",
      "Epoch 3/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1335\n",
      "Epoch 4/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0917\n",
      "Epoch 5/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9803 - loss: 0.0655\n",
      "Epoch 6/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0535\n",
      "Epoch 7/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0454\n",
      "Epoch 8/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.0579\n",
      "Epoch 9/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9823 - loss: 0.0568\n",
      "Epoch 10/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0662\n",
      "Epoch 11/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9947 - loss: 0.0219\n",
      "Epoch 12/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9925 - loss: 0.0228\n",
      "Epoch 13/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0121\n",
      "Epoch 14/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0181\n",
      "Epoch 15/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0082\n",
      "Epoch 16/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0043\n",
      "Epoch 17/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0083\n",
      "Epoch 18/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9858 - loss: 0.0663\n",
      "Epoch 19/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1942\n",
      "Epoch 20/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1670\n",
      "Epoch 21/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0523\n",
      "Epoch 22/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0209\n",
      "Epoch 23/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.0183\n",
      "Epoch 24/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0101\n",
      "Epoch 25/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0055\n",
      "Epoch 26/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 8.3861e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0033\n",
      "Epoch 28/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.8820e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0056\n",
      "Epoch 30/30\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.8594e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f24a73df90>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class AudioDataset:\n",
    "    def __init__(self, csv_path, audio_folder):\n",
    "        self.csv_path = csv_path\n",
    "        self.audio_folder = audio_folder\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_encoder.fit(self.data['Path'])  # Assuming 'label' is the column containing ground truth labels\n",
    "    \n",
    "    def get_data_at_index(self, index):\n",
    "        if index < 0 or index >= len(self.data):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        row = self.data.iloc[index]\n",
    "        audio_file = str(row(['Path']))\n",
    "        audio, sample_rate = librosa.load(audio_file, res_type='scipy')  # Load audio file\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate)  # Compute Mel spectrogram\n",
    "        mel_spectrogram = np.expand_dims(mel_spectrogram, axis=0)  # Add batch dimension\n",
    "        \n",
    "        ground_truth = self.label_encoder.transform([row['Path']])[0]  # Encode ground truth label\n",
    "        \n",
    "        # Assuming you have a function to get pseudo labels based on model inference\n",
    "        pseudo_label = self.get_pseudo_label(audio)  # Get pseudo label for audio\n",
    "        \n",
    "        return {\n",
    "            'file': row['Path'],\n",
    "            'audio': audio.reshape(1, -1),  # Reshape audio to [1, T]\n",
    "            'mel': mel_spectrogram,  # Mel spectrogram shape: [1, F, T]\n",
    "            'gt': ground_truth,\n",
    "            'pseudo': pseudo_label\n",
    "        }\n",
    "    \n",
    "    def get_pseudo_label(self, audio):\n",
    "        # Placeholder function for generating pseudo labels (replace with actual implementation)\n",
    "        # This could involve loading a trained model and performing inference on the audio\n",
    "        return 0  # Placeholder label for illustration\n",
    "    \n",
    "# Example usage:\n",
    "csv_path = 'TinySOL_metadata (1).csv'\n",
    "audio_folder = 'path/to/audio/folder'\n",
    "dataset = AudioDataset(csv_path, audio_folder)\n",
    "\n",
    "# Get data at index 0\n",
    "data_at_index_0 = dataset.get_data_at_index(0)\n",
    "print(data_at_index_0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
